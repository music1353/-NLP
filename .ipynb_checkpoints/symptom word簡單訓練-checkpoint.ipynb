{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 資料預處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from /Users/s960405s/pythonRepository/SemanticAnalysis/jieba_dict/dict.txt.big ...\n",
      "Loading model from cache /var/folders/vt/8y8lcrqn6s19299xv1vwm25m0000gn/T/jieba.u44e9641eb3a06c7bcf83bd1c44fcbc7a.cache\n",
      "Loading model cost 2.110 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\ufeff 咳嗽 ', '喉嚨 ', '喉嚨痛 ', '喉嚨 不 舒服 ', '喉嚨 癢 ', '喉嚨 發炎 ', '喉嚨 ', '喉嚨 乾 ', '喉嚨 腫 ', '咳嗽 ', '喉嚨 ', '喉嚨痛 ', '喉嚨 不 舒服 ', '喉嚨 癢 ', '喉嚨 發炎 ', '喉嚨 ', '喉嚨 乾 ', '喉嚨 腫 ', '咳嗽 ', '喉嚨 ', '喉嚨痛 ', '喉嚨 不 舒服 ', '喉嚨 癢 ', '喉嚨 發炎 ', '喉嚨 ', '喉嚨 乾 ', '喉嚨 腫 ', '火 大 ', '火氣 大 ', '火 很大 ', '很火 ', '煩躁 ', '很煩 ', '厭煩 ', '火 大 ', '火氣 大 ', '火 很大 ', '很火 ', '煩躁 ', '很煩 ', '厭煩 ', '火 大 ', '火氣 大 ', '火 很大 ', '很火 ', '煩躁 ', '很煩 ', '厭煩 ', '腹痛 ', '肚子痛 ', '肚子 不 舒服 ', '肚子 怪怪的 ', '肚子疼 ', '肚子 脹 ', '腹部 痛 ', '腹痛 ', '肚子痛 ', '肚子 不 舒服 ', '肚子 怪怪的 ', '肚子疼 ', '肚子 脹 ', '腹部 痛 ', '腹痛 ', '肚子痛 ', '肚子 不 舒服 ', '肚子 怪怪的 ', '肚子疼 ', '肚子 脹 ', '腹部 痛']\n",
      "['0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2']\n"
     ]
    }
   ],
   "source": [
    "# 讀資料\n",
    "import jieba\n",
    "\n",
    "text = []\n",
    "mark = []\n",
    "\n",
    "# set jieba dict\n",
    "jieba.set_dictionary('jieba_dict/dict.txt.big')\n",
    "\n",
    "# 讀text資料\n",
    "with open('symptom_words/text.txt', 'r') as label_text:\n",
    "    for line in label_text:\n",
    "        seg_line = jieba.cut(line, cut_all=False)\n",
    "        text.append(' '.join(seg_line).rstrip('\\n'))\n",
    "        \n",
    "# 讀mark資料\n",
    "with open('symptom_words/mark.txt', 'r') as feacture_text:\n",
    "    for line in feacture_text:\n",
    "        mark.append(line.rstrip('\\n'))        \n",
    "        \n",
    "print(text)\n",
    "print(mark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# 建立token\n",
    "token = Tokenizer()\n",
    "token.fit_on_texts(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69\n"
     ]
    }
   ],
   "source": [
    "print(token.document_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'喉嚨': 1, '肚子': 2, '不': 3, '舒服': 4, '火': 5, '大': 6, '咳嗽': 7, '喉嚨痛': 8, '癢': 9, '發炎': 10, '乾': 11, '腫': 12, '火氣': 13, '很大': 14, '很火': 15, '煩躁': 16, '很煩': 17, '厭煩': 18, '腹痛': 19, '肚子痛': 20, '怪怪的': 21, '肚子疼': 22, '脹': 23, '腹部': 24, '痛': 25, '\\ufeff': 26}\n"
     ]
    }
   ],
   "source": [
    "print(token.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 把text轉為數字list\n",
    "text_seq = token.texts_to_sequences(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[26, 7], [1], [8], [1, 3, 4], [1, 9], [1, 10], [1], [1, 11], [1, 12], [7], [1], [8], [1, 3, 4], [1, 9], [1, 10], [1], [1, 11], [1, 12], [7], [1], [8], [1, 3, 4], [1, 9], [1, 10], [1], [1, 11], [1, 12], [5, 6], [13, 6], [5, 14], [15], [16], [17], [18], [5, 6], [13, 6], [5, 14], [15], [16], [17], [18], [5, 6], [13, 6], [5, 14], [15], [16], [17], [18], [19], [20], [2, 3, 4], [2, 21], [22], [2, 23], [24, 25], [19], [20], [2, 3, 4], [2, 21], [22], [2, 23], [24, 25], [19], [20], [2, 3, 4], [2, 21], [22], [2, 23], [24, 25]]\n"
     ]
    }
   ],
   "source": [
    "print(text_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 讓每筆list長度都是4\n",
    "train_text = sequence.pad_sequences(text_seq, maxlen=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0 26  7]\n",
      " [ 0  0  0  1]\n",
      " [ 0  0  0  8]\n",
      " [ 0  1  3  4]\n",
      " [ 0  0  1  9]\n",
      " [ 0  0  1 10]\n",
      " [ 0  0  0  1]\n",
      " [ 0  0  1 11]\n",
      " [ 0  0  1 12]\n",
      " [ 0  0  0  7]\n",
      " [ 0  0  0  1]\n",
      " [ 0  0  0  8]\n",
      " [ 0  1  3  4]\n",
      " [ 0  0  1  9]\n",
      " [ 0  0  1 10]\n",
      " [ 0  0  0  1]\n",
      " [ 0  0  1 11]\n",
      " [ 0  0  1 12]\n",
      " [ 0  0  0  7]\n",
      " [ 0  0  0  1]\n",
      " [ 0  0  0  8]\n",
      " [ 0  1  3  4]\n",
      " [ 0  0  1  9]\n",
      " [ 0  0  1 10]\n",
      " [ 0  0  0  1]\n",
      " [ 0  0  1 11]\n",
      " [ 0  0  1 12]\n",
      " [ 0  0  5  6]\n",
      " [ 0  0 13  6]\n",
      " [ 0  0  5 14]\n",
      " [ 0  0  0 15]\n",
      " [ 0  0  0 16]\n",
      " [ 0  0  0 17]\n",
      " [ 0  0  0 18]\n",
      " [ 0  0  5  6]\n",
      " [ 0  0 13  6]\n",
      " [ 0  0  5 14]\n",
      " [ 0  0  0 15]\n",
      " [ 0  0  0 16]\n",
      " [ 0  0  0 17]\n",
      " [ 0  0  0 18]\n",
      " [ 0  0  5  6]\n",
      " [ 0  0 13  6]\n",
      " [ 0  0  5 14]\n",
      " [ 0  0  0 15]\n",
      " [ 0  0  0 16]\n",
      " [ 0  0  0 17]\n",
      " [ 0  0  0 18]\n",
      " [ 0  0  0 19]\n",
      " [ 0  0  0 20]\n",
      " [ 0  2  3  4]\n",
      " [ 0  0  2 21]\n",
      " [ 0  0  0 22]\n",
      " [ 0  0  2 23]\n",
      " [ 0  0 24 25]\n",
      " [ 0  0  0 19]\n",
      " [ 0  0  0 20]\n",
      " [ 0  2  3  4]\n",
      " [ 0  0  2 21]\n",
      " [ 0  0  0 22]\n",
      " [ 0  0  2 23]\n",
      " [ 0  0 24 25]\n",
      " [ 0  0  0 19]\n",
      " [ 0  0  0 20]\n",
      " [ 0  2  3  4]\n",
      " [ 0  0  2 21]\n",
      " [ 0  0  0 22]\n",
      " [ 0  0  2 23]\n",
      " [ 0  0 24 25]]\n"
     ]
    }
   ],
   "source": [
    "print(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# one-hot encoding mark\n",
    "from keras.utils import np_utils\n",
    "\n",
    "mark_oneHot = np_utils.to_categorical(mark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mark_oneHot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 建模&訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import LSTM\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(output_dim=4, input_dim=26, input_length=4))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=256, activation='relu'))\n",
    "model.add(Dense(units=3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定義訓練方式\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# 開始訓練\n",
    "# 打散資料:shuffle=True,\n",
    "train_history = model.fit(train_text, mark_oneHot, batch_size=10, epochs=30, verbose=2, shuffle=True, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 評估\n",
    "scores = model.evaluate(train_text, mark_oneHot)\n",
    "scores[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = input('輸入要查詢的字詞：')\n",
    "seg_query = jieba.cut(query, cut_all=False)\n",
    "query_line = []\n",
    "query_line.append(' '.join(seg_query).rstrip('\\n'))\n",
    "print(query_line)\n",
    "\n",
    "input_seq = token.texts_to_sequences(query_line) # 轉成數字list\n",
    "print(input_seq)\n",
    "\n",
    "pad_input_seq = sequence.pad_sequences(input_seq, maxlen=4) # 長度轉為4\n",
    "\n",
    "predict_soft = model.predict(pad_input_seq)\n",
    "predict = model.predict_classes(pad_input_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0:咳嗽, 1:火大, 2:腹痛\n",
    "predict[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predict_soft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
