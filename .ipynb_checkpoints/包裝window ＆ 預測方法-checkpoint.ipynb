{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import all need module\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing import sequence\n",
    "import jieba\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "\n",
    "from keras.models import load_model\n",
    "model = load_model('train_models/1215_600mark_model.h5')      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# window & jieba cut\n",
    "\n",
    "import jieba\n",
    "\n",
    "def window_cut(sentence):\n",
    "    \n",
    "    if len(sentence)<=5:\n",
    "        seg_sen = jieba.cut(sentence, cut_all=False)\n",
    "        seg_sen_list = []\n",
    "        seg_sen_list.append(' '.join(seg_sen).rstrip('\\n'))\n",
    "        return seg_sen_list\n",
    "    \n",
    "    else:\n",
    "        count = 0\n",
    "        win_start = 0\n",
    "        win_end = 5\n",
    "        step_move = 2\n",
    "        window_list = []\n",
    "        \n",
    "        while( win_end <= len(sentence) ):\n",
    "            win_start = 0\n",
    "            win_end = 5\n",
    "    \n",
    "            win_start = win_start + step_move*count\n",
    "            win_end = win_end + step_move*count\n",
    "    \n",
    "            window_sentence = sentence[win_start:win_end]\n",
    "    \n",
    "            window_list.append( window_sentence )\n",
    "    \n",
    "            count = count +1\n",
    "        \n",
    "        return window_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# window處理過的句子那去預測\n",
    "import pickle\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "def load_train_token():\n",
    "    with open('train_models/1215_600mark_token.pickle', 'rb') as handle:\n",
    "        token = pickle.load(handle)\n",
    "        return token\n",
    "\n",
    "def after_window_predict(window_list, token, predict_symptom_dict):\n",
    "    \n",
    "    win_predict = []\n",
    "    \n",
    "    for sen in window_list:\n",
    "        query = sen\n",
    "        seg_query = jieba.cut(query, cut_all=False)\n",
    "        query_line = []\n",
    "        query_line.append(' '.join(seg_query).rstrip('\\n'))\n",
    "\n",
    "        input_seq = token.texts_to_sequences(query_line) # 轉成數字list\n",
    "\n",
    "        pad_input_seq = sequence.pad_sequences(input_seq, maxlen=4) # 長度轉為4\n",
    "\n",
    "        predict = model.predict_classes(pad_input_seq)\n",
    "        predict_soft = model.predict(pad_input_seq) # 機率分布\n",
    "    \n",
    "        # 如果沒超過某個機率不能列入 0.7, 0.8, 0.9\n",
    "        if max(predict_soft[0])<0.8:\n",
    "            pass\n",
    "        else:\n",
    "            win_predict.append( predict_symptom_dict[ predict[0] ] )\n",
    "        \n",
    "    win_predict = list(set(win_predict)) # 把重複的symptom刪除\n",
    "    \n",
    "    return win_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/vt/8y8lcrqn6s19299xv1vwm25m0000gn/T/jieba.cache\n",
      "Loading model cost 1.061 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s\n",
      "1/1 [==============================] - 0s\n",
      "1/1 [==============================] - 0s\n",
      "1/1 [==============================] - 0s\n",
      "1/1 [==============================] - 0s\n",
      "1/1 [==============================] - 0s\n",
      "1/1 [==============================] - 0s\n",
      "1/1 [==============================] - 0s\n",
      "1/1 [==============================] - 0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['筋骨痛', '胃痛']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window_list = window_cut('這幾天有點胃痛，而且已經腰酸背痛很久了')\n",
    "\n",
    "token = load_train_token()\n",
    "\n",
    "predict_symptom_dict = {0:'火大', 1:'咳嗽', 2:'高血壓', 3:'胃潰瘍', 4:'痰', 5:'風濕', 6:'筋骨痛',\n",
    "                        7:'胃痛', 8:'腎臟病', 9:'發炎', 10:'腸胃不順', 11:'水腫', 12:'糖尿病',\n",
    "                        13:'肝炎', 14:'中暑'}\n",
    "\n",
    "after_window_predict(window_list, token, predict_symptom_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
