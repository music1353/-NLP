{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 資料預處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\User\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.701 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['咳嗽 ', '喉嚨 ', '喉嚨 痛 ', '喉嚨 不 舒服 ', '喉嚨 癢 ', '喉嚨 發炎 ', '喉嚨 ', '喉嚨 乾 ', '喉嚨 腫 ', '咳嗽 ', '喉嚨 ', '喉嚨 痛 ', '喉嚨 不 舒服 ', '喉嚨 癢 ', '喉嚨 發炎 ', '喉嚨 ', '喉嚨 乾 ', '喉嚨 腫 ', '咳嗽 ', '喉嚨 ', '喉嚨 痛 ', '喉嚨 不 舒服 ', '喉嚨 癢 ', '喉嚨 發炎 ', '喉嚨 ', '喉嚨 乾 ', '喉嚨 腫 ', '火 大 ', '火氣 大 ', '火 很大 ', '很火 ', '煩躁 ', '很煩 ', '厭煩 ', '火 大 ', '火氣 大 ', '火 很大 ', '很火 ', '煩躁 ', '很煩 ', '厭煩 ', '火 大 ', '火氣 大 ', '火 很大 ', '很火 ', '煩躁 ', '很煩 ', '厭煩 ', '腹痛 ', '肚子痛 ', '肚子 不 舒服 ', '肚子 怪怪的 ', '肚子疼 ', '肚子 脹 ', '腹部 痛 ', '腹痛 ', '肚子痛 ', '肚子 不 舒服 ', '肚子 怪怪的 ', '肚子疼 ', '肚子 脹 ', '腹部 痛 ', '腹痛 ', '肚子痛 ', '肚子 不 舒服 ', '肚子 怪怪的 ', '肚子疼 ', '肚子 脹 ', '腹部 痛']\n",
      "['0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2']\n"
     ]
    }
   ],
   "source": [
    "# 讀資料\n",
    "import jieba\n",
    "\n",
    "text = []\n",
    "mark = []\n",
    "\n",
    "# 讀label資料\n",
    "with open('symptom_words/text.txt', 'r') as label_text:\n",
    "    for line in label_text:\n",
    "        seg_line = jieba.cut(line, cut_all=False)\n",
    "        text.append(' '.join(seg_line).rstrip('\\n'))\n",
    "        \n",
    "# 讀feacture資料\n",
    "with open('symptom_words/mark.txt', 'r') as feacture_text:\n",
    "    for line in feacture_text:\n",
    "        mark.append(line.rstrip('\\n'))        \n",
    "        \n",
    "print(text)\n",
    "print(mark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# 建立token\n",
    "token = Tokenizer()\n",
    "token.fit_on_texts(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69\n"
     ]
    }
   ],
   "source": [
    "print(token.document_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'喉嚨': 1, '肚子': 2, '痛': 3, '不': 4, '舒服': 5, '火': 6, '大': 7, '咳嗽': 8, '癢': 9, '發炎': 10, '乾': 11, '腫': 12, '火氣': 13, '很大': 14, '很火': 15, '煩躁': 16, '很煩': 17, '厭煩': 18, '腹痛': 19, '肚子痛': 20, '怪怪的': 21, '肚子疼': 22, '脹': 23, '腹部': 24}\n"
     ]
    }
   ],
   "source": [
    "print(token.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 把text轉為數字list\n",
    "text_seq = token.texts_to_sequences(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8], [1], [1, 3], [1, 4, 5], [1, 9], [1, 10], [1], [1, 11], [1, 12], [8], [1], [1, 3], [1, 4, 5], [1, 9], [1, 10], [1], [1, 11], [1, 12], [8], [1], [1, 3], [1, 4, 5], [1, 9], [1, 10], [1], [1, 11], [1, 12], [6, 7], [13, 7], [6, 14], [15], [16], [17], [18], [6, 7], [13, 7], [6, 14], [15], [16], [17], [18], [6, 7], [13, 7], [6, 14], [15], [16], [17], [18], [19], [20], [2, 4, 5], [2, 21], [22], [2, 23], [24, 3], [19], [20], [2, 4, 5], [2, 21], [22], [2, 23], [24, 3], [19], [20], [2, 4, 5], [2, 21], [22], [2, 23], [24, 3]]\n"
     ]
    }
   ],
   "source": [
    "print(text_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 讓每筆list長度都是4\n",
    "train_text = sequence.pad_sequences(text_seq, maxlen=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0  8]\n",
      " [ 0  0  0  1]\n",
      " [ 0  0  1  3]\n",
      " [ 0  1  4  5]\n",
      " [ 0  0  1  9]\n",
      " [ 0  0  1 10]\n",
      " [ 0  0  0  1]\n",
      " [ 0  0  1 11]\n",
      " [ 0  0  1 12]\n",
      " [ 0  0  0  8]\n",
      " [ 0  0  0  1]\n",
      " [ 0  0  1  3]\n",
      " [ 0  1  4  5]\n",
      " [ 0  0  1  9]\n",
      " [ 0  0  1 10]\n",
      " [ 0  0  0  1]\n",
      " [ 0  0  1 11]\n",
      " [ 0  0  1 12]\n",
      " [ 0  0  0  8]\n",
      " [ 0  0  0  1]\n",
      " [ 0  0  1  3]\n",
      " [ 0  1  4  5]\n",
      " [ 0  0  1  9]\n",
      " [ 0  0  1 10]\n",
      " [ 0  0  0  1]\n",
      " [ 0  0  1 11]\n",
      " [ 0  0  1 12]\n",
      " [ 0  0  6  7]\n",
      " [ 0  0 13  7]\n",
      " [ 0  0  6 14]\n",
      " [ 0  0  0 15]\n",
      " [ 0  0  0 16]\n",
      " [ 0  0  0 17]\n",
      " [ 0  0  0 18]\n",
      " [ 0  0  6  7]\n",
      " [ 0  0 13  7]\n",
      " [ 0  0  6 14]\n",
      " [ 0  0  0 15]\n",
      " [ 0  0  0 16]\n",
      " [ 0  0  0 17]\n",
      " [ 0  0  0 18]\n",
      " [ 0  0  6  7]\n",
      " [ 0  0 13  7]\n",
      " [ 0  0  6 14]\n",
      " [ 0  0  0 15]\n",
      " [ 0  0  0 16]\n",
      " [ 0  0  0 17]\n",
      " [ 0  0  0 18]\n",
      " [ 0  0  0 19]\n",
      " [ 0  0  0 20]\n",
      " [ 0  2  4  5]\n",
      " [ 0  0  2 21]\n",
      " [ 0  0  0 22]\n",
      " [ 0  0  2 23]\n",
      " [ 0  0 24  3]\n",
      " [ 0  0  0 19]\n",
      " [ 0  0  0 20]\n",
      " [ 0  2  4  5]\n",
      " [ 0  0  2 21]\n",
      " [ 0  0  0 22]\n",
      " [ 0  0  2 23]\n",
      " [ 0  0 24  3]\n",
      " [ 0  0  0 19]\n",
      " [ 0  0  0 20]\n",
      " [ 0  2  4  5]\n",
      " [ 0  0  2 21]\n",
      " [ 0  0  0 22]\n",
      " [ 0  0  2 23]\n",
      " [ 0  0 24  3]]\n"
     ]
    }
   ],
   "source": [
    "print(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# one-hot encoding mark\n",
    "from keras.utils import np_utils\n",
    "\n",
    "mark_oneHot = np_utils.to_categorical(mark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "print(mark_oneHot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 建模&訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(output_dim=4, input_dim=29, input_length=4))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=256, activation='relu'))\n",
    "model.add(Dense(units=3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 4, 4)              116       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               4352      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 5,239\n",
      "Trainable params: 5,239\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 62 samples, validate on 7 samples\n",
      "Epoch 1/30\n",
      "0s - loss: 0.6318 - acc: 0.6667 - val_loss: 0.6503 - val_acc: 0.6667\n",
      "Epoch 2/30\n",
      "0s - loss: 0.6244 - acc: 0.6667 - val_loss: 0.6607 - val_acc: 0.6667\n",
      "Epoch 3/30\n",
      "0s - loss: 0.6165 - acc: 0.6667 - val_loss: 0.6767 - val_acc: 0.6667\n",
      "Epoch 4/30\n",
      "0s - loss: 0.6070 - acc: 0.6667 - val_loss: 0.6853 - val_acc: 0.6667\n",
      "Epoch 5/30\n",
      "0s - loss: 0.5959 - acc: 0.6667 - val_loss: 0.7002 - val_acc: 0.6667\n",
      "Epoch 6/30\n",
      "0s - loss: 0.5812 - acc: 0.6667 - val_loss: 0.7134 - val_acc: 0.6667\n",
      "Epoch 7/30\n",
      "0s - loss: 0.5627 - acc: 0.6828 - val_loss: 0.7261 - val_acc: 0.6667\n",
      "Epoch 8/30\n",
      "0s - loss: 0.5400 - acc: 0.7473 - val_loss: 0.7397 - val_acc: 0.6667\n",
      "Epoch 9/30\n",
      "0s - loss: 0.5142 - acc: 0.7634 - val_loss: 0.7312 - val_acc: 0.6667\n",
      "Epoch 10/30\n",
      "0s - loss: 0.4843 - acc: 0.7688 - val_loss: 0.7089 - val_acc: 0.6190\n",
      "Epoch 11/30\n",
      "0s - loss: 0.4507 - acc: 0.8226 - val_loss: 0.6983 - val_acc: 0.6190\n",
      "Epoch 12/30\n",
      "0s - loss: 0.4166 - acc: 0.8656 - val_loss: 0.6893 - val_acc: 0.6190\n",
      "Epoch 13/30\n",
      "0s - loss: 0.3774 - acc: 0.8656 - val_loss: 0.6441 - val_acc: 0.6190\n",
      "Epoch 14/30\n",
      "0s - loss: 0.3412 - acc: 0.8656 - val_loss: 0.5987 - val_acc: 0.6190\n",
      "Epoch 15/30\n",
      "0s - loss: 0.3066 - acc: 0.8710 - val_loss: 0.5292 - val_acc: 0.6667\n",
      "Epoch 16/30\n",
      "0s - loss: 0.2747 - acc: 0.9086 - val_loss: 0.4724 - val_acc: 0.7619\n",
      "Epoch 17/30\n",
      "0s - loss: 0.2406 - acc: 0.9301 - val_loss: 0.4352 - val_acc: 0.8571\n",
      "Epoch 18/30\n",
      "0s - loss: 0.2103 - acc: 0.9516 - val_loss: 0.3874 - val_acc: 0.8571\n",
      "Epoch 19/30\n",
      "0s - loss: 0.1825 - acc: 0.9516 - val_loss: 0.3488 - val_acc: 0.9048\n",
      "Epoch 20/30\n",
      "0s - loss: 0.1577 - acc: 0.9677 - val_loss: 0.3197 - val_acc: 0.9048\n",
      "Epoch 21/30\n",
      "0s - loss: 0.1335 - acc: 0.9946 - val_loss: 0.2727 - val_acc: 1.0000\n",
      "Epoch 22/30\n",
      "0s - loss: 0.1138 - acc: 1.0000 - val_loss: 0.1988 - val_acc: 1.0000\n",
      "Epoch 23/30\n",
      "0s - loss: 0.0940 - acc: 1.0000 - val_loss: 0.1474 - val_acc: 1.0000\n",
      "Epoch 24/30\n",
      "0s - loss: 0.0809 - acc: 1.0000 - val_loss: 0.1212 - val_acc: 1.0000\n",
      "Epoch 25/30\n",
      "0s - loss: 0.0683 - acc: 1.0000 - val_loss: 0.1086 - val_acc: 1.0000\n",
      "Epoch 26/30\n",
      "0s - loss: 0.0583 - acc: 1.0000 - val_loss: 0.1023 - val_acc: 1.0000\n",
      "Epoch 27/30\n",
      "0s - loss: 0.0499 - acc: 1.0000 - val_loss: 0.0937 - val_acc: 1.0000\n",
      "Epoch 28/30\n",
      "0s - loss: 0.0423 - acc: 1.0000 - val_loss: 0.0731 - val_acc: 1.0000\n",
      "Epoch 29/30\n",
      "0s - loss: 0.0363 - acc: 1.0000 - val_loss: 0.0607 - val_acc: 1.0000\n",
      "Epoch 30/30\n",
      "0s - loss: 0.0317 - acc: 1.0000 - val_loss: 0.0492 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# 定義訓練方式\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# 開始訓練\n",
    "train_history = model.fit(train_text, mark_oneHot, batch_size=10, epochs=30, verbose=2, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "32/69 [============>.................] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 評估\n",
    "scores = model.evaluate(train_text, mark_oneHot)\n",
    "scores[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輸入要查詢的字詞：我的肚子不太舒服\n",
      "['我 的 肚子 不太 舒服']\n",
      "[[2, 5]]\n",
      "1/1 [==============================] - 0s\n"
     ]
    }
   ],
   "source": [
    "query = input('輸入要查詢的字詞：')\n",
    "seg_query = jieba.cut(query, cut_all=False)\n",
    "query_line = []\n",
    "query_line.append(' '.join(seg_query).rstrip('\\n'))\n",
    "print(query_line)\n",
    "\n",
    "input_seq = token.texts_to_sequences(query_line) # 轉成數字list\n",
    "print(input_seq)\n",
    "\n",
    "pad_input_seq = sequence.pad_sequences(input_seq, maxlen=4) # 長度轉為4\n",
    "\n",
    "predict = model.predict_classes(pad_input_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2], dtype=int64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
