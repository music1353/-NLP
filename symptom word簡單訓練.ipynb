{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 資料預處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from /Users/s960405s/pythonRepository/SemanticAnalysis/jieba_dict/dict.txt.big ...\n",
      "Loading model from cache /var/folders/vt/8y8lcrqn6s19299xv1vwm25m0000gn/T/jieba.u44e9641eb3a06c7bcf83bd1c44fcbc7a.cache\n",
      "Loading model cost 1.914 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['咳嗽 ', '喉嚨 ', '喉嚨痛 ', '喉嚨 不 舒服 ', '喉嚨 癢 ', '喉嚨 發炎 ', '喉嚨 ', '喉嚨 乾 ', '喉嚨 腫 ', '咳嗽 ', '喉嚨 ', '喉嚨痛 ', '喉嚨 不 舒服 ', '喉嚨 癢 ', '喉嚨 發炎 ', '喉嚨 ', '喉嚨 乾 ', '喉嚨 腫 ', '咳嗽 ', '喉嚨 ', '喉嚨痛 ', '喉嚨 不 舒服 ', '喉嚨 癢 ', '喉嚨 發炎 ', '喉嚨 ', '喉嚨 乾 ', '喉嚨 腫 ', '火 大 ', '火氣 大 ', '火 很大 ', '很火 ', '煩躁 ', '很煩 ', '厭煩 ', '火 大 ', '火氣 大 ', '火 很大 ', '很火 ', '煩躁 ', '很煩 ', '厭煩 ', '火 大 ', '火氣 大 ', '火 很大 ', '很火 ', '煩躁 ', '很煩 ', '厭煩 ', '腹痛 ', '肚子痛 ', '肚子 不 舒服 ', '肚子 怪怪的 ', '肚子疼 ', '肚子 脹 ', '腹部 痛 ', '腹痛 ', '肚子痛 ', '肚子 不 舒服 ', '肚子 怪怪的 ', '肚子疼 ', '肚子 脹 ', '腹部 痛 ', '腹痛 ', '肚子痛 ', '肚子 不 舒服 ', '肚子 怪怪的 ', '肚子疼 ', '肚子 脹 ', '腹部 痛']\n",
      "['0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2']\n"
     ]
    }
   ],
   "source": [
    "# 讀資料\n",
    "\n",
    "import jieba\n",
    "\n",
    "text = []\n",
    "mark = []\n",
    "\n",
    "# set jieba dict\n",
    "jieba.set_dictionary('jieba_dict/dict.txt.big')\n",
    "\n",
    "# 讀text資料\n",
    "with open('symptom_words/text.txt', 'r', encoding=\"big5\") as label_text:\n",
    "    for line in label_text:\n",
    "        seg_line = jieba.cut(line, cut_all=False)\n",
    "        text.append(' '.join(seg_line).rstrip('\\n'))\n",
    "        \n",
    "# 讀mark資料\n",
    "with open('symptom_words/mark.txt', 'r') as feacture_text:\n",
    "    for line in feacture_text:\n",
    "        mark.append(line.rstrip('\\n'))        \n",
    "        \n",
    "print(text)\n",
    "print(mark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# 建立token\n",
    "token = Tokenizer()\n",
    "token.fit_on_texts(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69\n"
     ]
    }
   ],
   "source": [
    "print(token.document_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'喉嚨': 1, '肚子': 2, '不': 3, '舒服': 4, '火': 5, '大': 6, '咳嗽': 7, '喉嚨痛': 8, '癢': 9, '發炎': 10, '乾': 11, '腫': 12, '火氣': 13, '很大': 14, '很火': 15, '煩躁': 16, '很煩': 17, '厭煩': 18, '腹痛': 19, '肚子痛': 20, '怪怪的': 21, '肚子疼': 22, '脹': 23, '腹部': 24, '痛': 25}\n"
     ]
    }
   ],
   "source": [
    "print(token.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 把text轉為數字list\n",
    "text_seq = token.texts_to_sequences(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7], [1], [8], [1, 3, 4], [1, 9], [1, 10], [1], [1, 11], [1, 12], [7], [1], [8], [1, 3, 4], [1, 9], [1, 10], [1], [1, 11], [1, 12], [7], [1], [8], [1, 3, 4], [1, 9], [1, 10], [1], [1, 11], [1, 12], [5, 6], [13, 6], [5, 14], [15], [16], [17], [18], [5, 6], [13, 6], [5, 14], [15], [16], [17], [18], [5, 6], [13, 6], [5, 14], [15], [16], [17], [18], [19], [20], [2, 3, 4], [2, 21], [22], [2, 23], [24, 25], [19], [20], [2, 3, 4], [2, 21], [22], [2, 23], [24, 25], [19], [20], [2, 3, 4], [2, 21], [22], [2, 23], [24, 25]]\n"
     ]
    }
   ],
   "source": [
    "print(text_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 讓每筆list長度都是4\n",
    "train_text = sequence.pad_sequences(text_seq, maxlen=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0  7]\n",
      " [ 0  0  0  1]\n",
      " [ 0  0  0  8]\n",
      " [ 0  1  3  4]\n",
      " [ 0  0  1  9]\n",
      " [ 0  0  1 10]\n",
      " [ 0  0  0  1]\n",
      " [ 0  0  1 11]\n",
      " [ 0  0  1 12]\n",
      " [ 0  0  0  7]\n",
      " [ 0  0  0  1]\n",
      " [ 0  0  0  8]\n",
      " [ 0  1  3  4]\n",
      " [ 0  0  1  9]\n",
      " [ 0  0  1 10]\n",
      " [ 0  0  0  1]\n",
      " [ 0  0  1 11]\n",
      " [ 0  0  1 12]\n",
      " [ 0  0  0  7]\n",
      " [ 0  0  0  1]\n",
      " [ 0  0  0  8]\n",
      " [ 0  1  3  4]\n",
      " [ 0  0  1  9]\n",
      " [ 0  0  1 10]\n",
      " [ 0  0  0  1]\n",
      " [ 0  0  1 11]\n",
      " [ 0  0  1 12]\n",
      " [ 0  0  5  6]\n",
      " [ 0  0 13  6]\n",
      " [ 0  0  5 14]\n",
      " [ 0  0  0 15]\n",
      " [ 0  0  0 16]\n",
      " [ 0  0  0 17]\n",
      " [ 0  0  0 18]\n",
      " [ 0  0  5  6]\n",
      " [ 0  0 13  6]\n",
      " [ 0  0  5 14]\n",
      " [ 0  0  0 15]\n",
      " [ 0  0  0 16]\n",
      " [ 0  0  0 17]\n",
      " [ 0  0  0 18]\n",
      " [ 0  0  5  6]\n",
      " [ 0  0 13  6]\n",
      " [ 0  0  5 14]\n",
      " [ 0  0  0 15]\n",
      " [ 0  0  0 16]\n",
      " [ 0  0  0 17]\n",
      " [ 0  0  0 18]\n",
      " [ 0  0  0 19]\n",
      " [ 0  0  0 20]\n",
      " [ 0  2  3  4]\n",
      " [ 0  0  2 21]\n",
      " [ 0  0  0 22]\n",
      " [ 0  0  2 23]\n",
      " [ 0  0 24 25]\n",
      " [ 0  0  0 19]\n",
      " [ 0  0  0 20]\n",
      " [ 0  2  3  4]\n",
      " [ 0  0  2 21]\n",
      " [ 0  0  0 22]\n",
      " [ 0  0  2 23]\n",
      " [ 0  0 24 25]\n",
      " [ 0  0  0 19]\n",
      " [ 0  0  0 20]\n",
      " [ 0  2  3  4]\n",
      " [ 0  0  2 21]\n",
      " [ 0  0  0 22]\n",
      " [ 0  0  2 23]\n",
      " [ 0  0 24 25]]\n"
     ]
    }
   ],
   "source": [
    "print(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# one-hot encoding mark\n",
    "from keras.utils import np_utils\n",
    "\n",
    "mark_oneHot = np_utils.to_categorical(mark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "print(mark_oneHot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 建模&訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import LSTM\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(output_dim=4, input_dim=26, input_length=4))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=256, activation='relu'))\n",
    "model.add(Dense(units=3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 4, 4)              104       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               4352      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 5,227\n",
      "Trainable params: 5,227\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 62 samples, validate on 7 samples\n",
      "Epoch 1/30\n",
      "0s - loss: 0.6374 - acc: 0.6667 - val_loss: 0.6415 - val_acc: 0.6667\n",
      "Epoch 2/30\n",
      "0s - loss: 0.6309 - acc: 0.6667 - val_loss: 0.6554 - val_acc: 0.6667\n",
      "Epoch 3/30\n",
      "0s - loss: 0.6252 - acc: 0.6667 - val_loss: 0.6704 - val_acc: 0.6667\n",
      "Epoch 4/30\n",
      "0s - loss: 0.6182 - acc: 0.6667 - val_loss: 0.6851 - val_acc: 0.6667\n",
      "Epoch 5/30\n",
      "0s - loss: 0.6108 - acc: 0.6667 - val_loss: 0.7007 - val_acc: 0.6667\n",
      "Epoch 6/30\n",
      "0s - loss: 0.6011 - acc: 0.6667 - val_loss: 0.7188 - val_acc: 0.6667\n",
      "Epoch 7/30\n",
      "0s - loss: 0.5873 - acc: 0.6667 - val_loss: 0.7345 - val_acc: 0.6667\n",
      "Epoch 8/30\n",
      "0s - loss: 0.5695 - acc: 0.6667 - val_loss: 0.7405 - val_acc: 0.6667\n",
      "Epoch 9/30\n",
      "0s - loss: 0.5473 - acc: 0.6774 - val_loss: 0.7453 - val_acc: 0.6667\n",
      "Epoch 10/30\n",
      "0s - loss: 0.5187 - acc: 0.7688 - val_loss: 0.7405 - val_acc: 0.6667\n",
      "Epoch 11/30\n",
      "0s - loss: 0.4839 - acc: 0.7957 - val_loss: 0.7231 - val_acc: 0.6667\n",
      "Epoch 12/30\n",
      "0s - loss: 0.4415 - acc: 0.8871 - val_loss: 0.7186 - val_acc: 0.6190\n",
      "Epoch 13/30\n",
      "0s - loss: 0.3981 - acc: 0.9140 - val_loss: 0.7207 - val_acc: 0.6190\n",
      "Epoch 14/30\n",
      "0s - loss: 0.3534 - acc: 0.9140 - val_loss: 0.6965 - val_acc: 0.6190\n",
      "Epoch 15/30\n",
      "0s - loss: 0.3094 - acc: 0.9140 - val_loss: 0.6319 - val_acc: 0.6190\n",
      "Epoch 16/30\n",
      "0s - loss: 0.2698 - acc: 0.9140 - val_loss: 0.6072 - val_acc: 0.6190\n",
      "Epoch 17/30\n",
      "0s - loss: 0.2339 - acc: 0.9140 - val_loss: 0.5766 - val_acc: 0.7143\n",
      "Epoch 18/30\n",
      "0s - loss: 0.2031 - acc: 0.9355 - val_loss: 0.5054 - val_acc: 0.7619\n",
      "Epoch 19/30\n",
      "0s - loss: 0.1747 - acc: 0.9462 - val_loss: 0.4348 - val_acc: 0.7619\n",
      "Epoch 20/30\n",
      "0s - loss: 0.1495 - acc: 0.9462 - val_loss: 0.3825 - val_acc: 0.7619\n",
      "Epoch 21/30\n",
      "0s - loss: 0.1297 - acc: 0.9624 - val_loss: 0.3111 - val_acc: 0.9048\n",
      "Epoch 22/30\n",
      "0s - loss: 0.1077 - acc: 1.0000 - val_loss: 0.2502 - val_acc: 1.0000\n",
      "Epoch 23/30\n",
      "0s - loss: 0.0916 - acc: 1.0000 - val_loss: 0.2017 - val_acc: 1.0000\n",
      "Epoch 24/30\n",
      "0s - loss: 0.0777 - acc: 1.0000 - val_loss: 0.1555 - val_acc: 1.0000\n",
      "Epoch 25/30\n",
      "0s - loss: 0.0659 - acc: 1.0000 - val_loss: 0.1215 - val_acc: 1.0000\n",
      "Epoch 26/30\n",
      "0s - loss: 0.0550 - acc: 1.0000 - val_loss: 0.1077 - val_acc: 1.0000\n",
      "Epoch 27/30\n",
      "0s - loss: 0.0465 - acc: 1.0000 - val_loss: 0.0902 - val_acc: 1.0000\n",
      "Epoch 28/30\n",
      "0s - loss: 0.0393 - acc: 1.0000 - val_loss: 0.0801 - val_acc: 1.0000\n",
      "Epoch 29/30\n",
      "0s - loss: 0.0338 - acc: 1.0000 - val_loss: 0.0714 - val_acc: 1.0000\n",
      "Epoch 30/30\n",
      "0s - loss: 0.0292 - acc: 1.0000 - val_loss: 0.0574 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# 定義訓練方式\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# 開始訓練\n",
    "# 打散資料:shuffle=True,\n",
    "train_history = model.fit(train_text, mark_oneHot, batch_size=10, epochs=30, verbose=2, shuffle=True, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "32/69 [============>.................] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 評估\n",
    "scores = model.evaluate(train_text, mark_oneHot)\n",
    "scores[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輸入要查詢的字詞：歐霸好帥\n",
      "['歐霸 好帥']\n",
      "[[]]\n",
      "1/1 [==============================] - 0s\n"
     ]
    }
   ],
   "source": [
    "query = input('輸入要查詢的字詞：')\n",
    "seg_query = jieba.cut(query, cut_all=False)\n",
    "query_line = []\n",
    "query_line.append(' '.join(seg_query).rstrip('\\n'))\n",
    "print(query_line)\n",
    "\n",
    "input_seq = token.texts_to_sequences(query_line) # 轉成數字list\n",
    "print(input_seq)\n",
    "\n",
    "pad_input_seq = sequence.pad_sequences(input_seq, maxlen=4) # 長度轉為4\n",
    "\n",
    "predict_soft = model.predict(pad_input_seq)\n",
    "predict = model.predict_classes(pad_input_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0:咳嗽, 1:火大, 2:腹痛\n",
    "predict[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.33862841  0.26211768  0.3992539 ]]\n"
     ]
    }
   ],
   "source": [
    "print(predict_soft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
